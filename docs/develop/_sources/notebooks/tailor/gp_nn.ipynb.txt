{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d553745a",
   "metadata": {},
   "source": [
    "# Mixing TensorFlow models with GPflow\n",
    "\n",
    "This notebook explores the combination of Keras TensorFlow neural networks with GPflow models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8277ce78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T11:21:37.644098Z",
     "iopub.status.busy": "2022-05-23T11:21:37.643790Z",
     "iopub.status.idle": "2022-05-23T11:21:41.588143Z",
     "shell.execute_reply": "2022-05-23T11:21:41.587420Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 11:21:38.033806: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-23 11:21:38.033839: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/circleci/project/gpflow/experimental/utils.py:42: UserWarning: You're calling gpflow.experimental.check_shapes.decorator.check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import gpflow\n",
    "from gpflow.ci_utils import ci_niter\n",
    "from scipy.cluster.vq import kmeans2\n",
    "\n",
    "from typing import Dict, Optional, Tuple\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import gpflow\n",
    "from gpflow.utilities import to_default_float\n",
    "\n",
    "iterations = ci_niter(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c007b5e",
   "metadata": {},
   "source": [
    "## Convolutional network inside a GPflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a95995a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T11:21:41.591955Z",
     "iopub.status.busy": "2022-05-23T11:21:41.591217Z",
     "iopub.status.idle": "2022-05-23T11:21:44.758401Z",
     "shell.execute_reply": "2022-05-23T11:21:44.757459Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 11:21:41.602064: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /home/circleci/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c0cd4809dd4f41b393955c64c52a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...:   0%|          | 0/4 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to /home/circleci/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 11:21:42.701010: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-23 11:21:42.701058: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-23 11:21:42.701087: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (0ad0ab90cb53): /proc/driver/nvidia/version does not exist\n",
      "2022-05-23 11:21:42.701434: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/circleci/project/gpflow/experimental/utils.py:42: UserWarning: You're calling gpflow.experimental.check_shapes.checker.ShapeChecker.__init__ which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method ShapeChecker._parse_checks of <gpflow.experimental.check_shapes.checker.ShapeChecker object at 0x7f4fd42026b0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: annotated name 'shape' can't be nonlocal (__autograph_generated_filex53euizq.py, line 72)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method ShapeChecker._parse_checks of <gpflow.experimental.check_shapes.checker.ShapeChecker object at 0x7f4fd42026b0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: annotated name 'shape' can't be nonlocal (__autograph_generated_filex53euizq.py, line 72)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method ShapeChecker._parse_checks of <gpflow.experimental.check_shapes.checker.ShapeChecker object at 0x7f4fd42026b0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: annotated name 'shape' can't be nonlocal (__autograph_generated_filex53euizq.py, line 72)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "original_dataset, info = tfds.load(name=\"mnist\", split=tfds.Split.TRAIN, with_info=True)\n",
    "total_num_data = info.splits[\"train\"].num_examples\n",
    "image_shape = info.features[\"image\"].shape\n",
    "image_size = tf.reduce_prod(image_shape)\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "def map_fn(input_slice: Dict[str, tf.Tensor]):\n",
    "    updated = input_slice\n",
    "    image = to_default_float(updated[\"image\"]) / 255.0\n",
    "    label = to_default_float(updated[\"label\"])\n",
    "    return tf.reshape(image, [-1, image_size]), label\n",
    "\n",
    "\n",
    "autotune = tf.data.experimental.AUTOTUNE\n",
    "dataset = (\n",
    "    original_dataset.shuffle(1024)\n",
    "    .batch(batch_size, drop_remainder=True)\n",
    "    .map(map_fn, num_parallel_calls=autotune)\n",
    "    .prefetch(autotune)\n",
    "    .repeat()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3972fc0",
   "metadata": {},
   "source": [
    "Here we'll use the GPflow functionality, but put a non-GPflow model inside the kernel.\\\n",
    "Vanilla ConvNet. This gets 97.3% accuracy on MNIST when used on its own (+ final linear layer) after 20K iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e86fc671",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T11:21:44.761739Z",
     "iopub.status.busy": "2022-05-23T11:21:44.761373Z",
     "iopub.status.idle": "2022-05-23T11:21:44.770459Z",
     "shell.execute_reply": "2022-05-23T11:21:44.769574Z"
    }
   },
   "outputs": [],
   "source": [
    "class KernelWithConvNN(gpflow.kernels.Kernel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_shape: Tuple,\n",
    "        output_dim: int,\n",
    "        base_kernel: gpflow.kernels.Kernel,\n",
    "        batch_size: Optional[int] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        with self.name_scope:\n",
    "            self.base_kernel = base_kernel\n",
    "            input_size = int(tf.reduce_prod(image_shape))\n",
    "            input_shape = (input_size,)\n",
    "\n",
    "            self.cnn = tf.keras.Sequential(\n",
    "                [\n",
    "                    tf.keras.layers.InputLayer(input_shape=input_shape, batch_size=batch_size),\n",
    "                    tf.keras.layers.Reshape(image_shape),\n",
    "                    tf.keras.layers.Conv2D(\n",
    "                        filters=32, kernel_size=image_shape[:-1], padding=\"same\", activation=\"relu\"\n",
    "                    ),\n",
    "                    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "                    tf.keras.layers.Conv2D(\n",
    "                        filters=64, kernel_size=(5, 5), padding=\"same\", activation=\"relu\"\n",
    "                    ),\n",
    "                    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "                    tf.keras.layers.Flatten(),\n",
    "                    tf.keras.layers.Dense(output_dim, activation=\"relu\"),\n",
    "                    tf.keras.layers.Lambda(to_default_float),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            self.cnn.build()\n",
    "\n",
    "    def K(self, a_input: tf.Tensor, b_input: Optional[tf.Tensor] = None) -> tf.Tensor:\n",
    "        transformed_a = self.cnn(a_input)\n",
    "        transformed_b = self.cnn(b_input) if b_input is not None else b_input\n",
    "        return self.base_kernel.K(transformed_a, transformed_b)\n",
    "\n",
    "    def K_diag(self, a_input: tf.Tensor) -> tf.Tensor:\n",
    "        transformed_a = self.cnn(a_input)\n",
    "        return self.base_kernel.K_diag(transformed_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a1ec15",
   "metadata": {},
   "source": [
    "$K_{uf}$ is in ConvNN output space, therefore we need to update `Kuf` multidispatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0871495",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T11:21:44.773229Z",
     "iopub.status.busy": "2022-05-23T11:21:44.772879Z",
     "iopub.status.idle": "2022-05-23T11:21:44.778356Z",
     "shell.execute_reply": "2022-05-23T11:21:44.777521Z"
    }
   },
   "outputs": [],
   "source": [
    "class KernelSpaceInducingPoints(gpflow.inducing_variables.InducingPoints):\n",
    "    pass\n",
    "\n",
    "\n",
    "@gpflow.covariances.Kuu.register(KernelSpaceInducingPoints, KernelWithConvNN)\n",
    "def Kuu(inducing_variable, kernel, jitter=None):\n",
    "    func = gpflow.covariances.Kuu.dispatch(\n",
    "        gpflow.inducing_variables.InducingPoints, gpflow.kernels.Kernel\n",
    "    )\n",
    "    return func(inducing_variable, kernel.base_kernel, jitter=jitter)\n",
    "\n",
    "\n",
    "@gpflow.covariances.Kuf.register(KernelSpaceInducingPoints, KernelWithConvNN, object)\n",
    "def Kuf(inducing_variable, kernel, a_input):\n",
    "    return kernel.base_kernel(inducing_variable.Z, kernel.cnn(a_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b250060",
   "metadata": {},
   "source": [
    "Now we are ready to create and initialize the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f595521c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T11:21:44.781661Z",
     "iopub.status.busy": "2022-05-23T11:21:44.781317Z",
     "iopub.status.idle": "2022-05-23T11:21:49.896521Z",
     "shell.execute_reply": "2022-05-23T11:21:49.895181Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 11:21:44.957639: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "num_mnist_classes = 10\n",
    "output_dim = 5\n",
    "num_inducing_points = 100\n",
    "images_subset, labels_subset = next(iter(dataset.batch(32)))\n",
    "images_subset = tf.reshape(images_subset, [-1, image_size])\n",
    "labels_subset = tf.reshape(labels_subset, [-1, 1])\n",
    "\n",
    "kernel = KernelWithConvNN(\n",
    "    image_shape, output_dim, gpflow.kernels.SquaredExponential(), batch_size=batch_size\n",
    ")\n",
    "\n",
    "likelihood = gpflow.likelihoods.MultiClass(num_mnist_classes)\n",
    "\n",
    "inducing_variable_kmeans = kmeans2(images_subset.numpy(), num_inducing_points, minit=\"points\")[0]\n",
    "inducing_variable_cnn = kernel.cnn(inducing_variable_kmeans)\n",
    "inducing_variable = KernelSpaceInducingPoints(inducing_variable_cnn)\n",
    "\n",
    "model = gpflow.models.SVGP(\n",
    "    kernel,\n",
    "    likelihood,\n",
    "    inducing_variable=inducing_variable,\n",
    "    num_data=total_num_data,\n",
    "    num_latent_gps=num_mnist_classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab82c67",
   "metadata": {},
   "source": [
    "And start optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2ac6d45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T11:21:49.901061Z",
     "iopub.status.busy": "2022-05-23T11:21:49.900494Z",
     "iopub.status.idle": "2022-05-23T11:22:27.559696Z",
     "shell.execute_reply": "2022-05-23T11:22:27.558942Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 11:21:49.941802: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "data_iterator = iter(dataset)\n",
    "adam_opt = tf.optimizers.Adam(0.001)\n",
    "\n",
    "training_loss = model.training_loss_closure(data_iterator)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def optimization_step():\n",
    "    adam_opt.minimize(training_loss, var_list=model.trainable_variables)\n",
    "\n",
    "\n",
    "for _ in range(iterations):\n",
    "    optimization_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e788ce3e",
   "metadata": {},
   "source": [
    "Let's do predictions after training. Don't expect that we will get a good accuracy, because we haven't run training for long enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5d87c38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T11:22:27.562866Z",
     "iopub.status.busy": "2022-05-23T11:22:27.562526Z",
     "iopub.status.idle": "2022-05-23T11:22:38.305459Z",
     "shell.execute_reply": "2022-05-23T11:22:38.304543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 43.1641%\n"
     ]
    }
   ],
   "source": [
    "m, v = model.predict_y(images_subset)\n",
    "preds = np.argmax(m, 1).reshape(labels_subset.numpy().shape)\n",
    "correct = preds == labels_subset.numpy().astype(int)\n",
    "acc = np.average(correct.astype(float)) * 100.0\n",
    "\n",
    "print(\"Accuracy is {:.4f}%\".format(acc))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,.pct.py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0b56999d9a4c486a82c4b90820d06319": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "222405681e244925a62f7ba9f1c01ce9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2e058b76008142efaf19454110c80e0b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0b56999d9a4c486a82c4b90820d06319",
       "placeholder": "​",
       "style": "IPY_MODEL_c7f1d4394b5843b1a0597204a68c094a",
       "value": " 4/4 [00:00&lt;00:00, 10.96 file/s]"
      }
     },
     "41c0cd4809dd4f41b393955c64c52a42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_97e1a345692a4544a945e36c507f412c",
        "IPY_MODEL_e1972b8e9d42487e85b7a2bed28ae642",
        "IPY_MODEL_2e058b76008142efaf19454110c80e0b"
       ],
       "layout": "IPY_MODEL_4e6db149684844d4b6a23710e9e58ef2"
      }
     },
     "4e6db149684844d4b6a23710e9e58ef2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "97e1a345692a4544a945e36c507f412c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_222405681e244925a62f7ba9f1c01ce9",
       "placeholder": "​",
       "style": "IPY_MODEL_aa14a246e0ea47908d246afc476d86df",
       "value": "Dl Completed...: 100%"
      }
     },
     "aa14a246e0ea47908d246afc476d86df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c25402b91b2b4ceba7f801a657b88afa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c7f1d4394b5843b1a0597204a68c094a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e1972b8e9d42487e85b7a2bed28ae642": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fe246bdc806b4c55be404b6ca8050a3d",
       "max": 4.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c25402b91b2b4ceba7f801a657b88afa",
       "value": 4.0
      }
     },
     "fe246bdc806b4c55be404b6ca8050a3d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
